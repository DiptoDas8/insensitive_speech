{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script gives an end-to-end RAG process using Langsmith tracing, OpenAI chat models, embeddings, and vector stores. \n",
    "\n",
    "I have loaded and split documents, executed tool calls for retrieval operations, and generated AI responses using a graph based workflow. You can refer to this link for more details about LangChain: https://python.langchain.com/docs/introduction/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a .venv environment for this project.\n",
    "\n",
    "Posts activating the environment, below langchain dependencies are installed.\n",
    "\n",
    "```python\n",
    "pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "pip install -qU \"langchain[openai]\"\n",
    "pip install -qU langchain-openai\n",
    "pip install -qU langchain-chroma\n",
    "pip install -qU langchain_community pypdf\n",
    "pip install --upgrade --quiet langgraph langchain-community beautifulsoup4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langsmith for tracing (Optional)\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "# Prompt the user to enter the Langsmith API key securely.\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Chat Model: OpenAI GPT-4 Mini\n",
    "# -----------------------------\n",
    "\n",
    "# Prompts the user to enter OPENAI_API_KEY securely.\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Embeddings Configuration\n",
    "# -------------------------\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Vector Store Configuration\n",
    "# -----------------------------\n",
    "\n",
    "# Create a vector store based on Chroma for semantic similarity search.\n",
    "from langchain_chroma import Chroma\n",
    "vector_store = Chroma(embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate # Provides chat templates but I have used SystemMessage instead of this.\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import MessagesState, StateGraph\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Load the PDF file(s)\n",
    "# ----------------------\n",
    "\n",
    "file_path = \"data/Social Media Interactions.pdf\" # Kindly replace with the path to your PDF file\n",
    "loader = PyPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® Word for Microsoft 365', 'creator': 'Microsoft® Word for Microsoft 365', 'creationdate': '2025-02-05T11:51:48-05:00', 'author': 'Chauhan, Ankit Singh', 'moddate': '2025-02-05T11:51:48-05:00', 'source': 'data/Social Media Interactions.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'}, page_content=\"Social Media Interaction 1 \\nThis social media interaction revolves around the 2016 Holey Artisan Bakery attack in Dhaka, \\nBangladesh, which targeted foreigners and Bangladeshi citizens. The initial post by author \\nexpresses relief at not having attended a private university, implying that private universities are \\nsomehow associated with the victims of the attack. \\nIt's understandable to feel strong emotions about the Holey Artisan attack, a tragic event that \\naffected many. However, it's important to remember that generalizations about entire groups of \\npeople can be harmful and inaccurate. Private universities in Bangladesh are attended by students \\nfrom diverse backgrounds, and associating them with the victims of this specific attack \\nperpetuates unhelpful stereotypes. Let's focus on promoting understanding and empathy instead \\nof making sweeping judgments. \\nThe connection drawn between private universities and the Holey Artisan victims could fuel \\nprejudice against students from affluent backgrounds, who often attend private institutions. This \\ntype of generalization can lead to discrimination and social exclusion. The sentiment expressed by \\nthe author reflects a broader societal bias that sometimes associates certain groups with privilege \\nor perceived culpability in incidents like the Holey Artisan attack. This kind of thinking can \\ncontribute to a climate of fear and mistrust. \\n \\nSocial Media Interaction 2 \\nThis social media post appears to be a part of an ongoing discussion. While the content itself does \\nnot contain explicit hate speech, the phrase 'বাঙালি আগুন ধলিয়ে লিয়েযে' ('Bengalis have started \\nfires') is highly problematic. This statement evokes historical tensions and stereotypes surrounding \\nBengali dominance in Bangladeshi society. \\nThe phrase could be interpreted as inciting violence or hostility towards Bengalis. It reinforces \\nharmful stereotypes about Bengalis being aggressive or destructive. It may contribute to a climate \\nof fear and mistrust between different ethnic groups. \\n \\nSocial Media Interaction 3 \\nAuthor: 'ইউলিলিএফ চাযে সাধািণ চাকমািা যেন োত্রযিি ময া কযি ৩ িাবব য যেিা স্বাধীন করুক। \\nইউলিলিএফ োত্রযিিযক সামযন যিযে আযদািন কিয যে। েেনই আলমব চযি আযস  েন  ািা লিেু \\nহটয যে।' , 'অিযিলি ইউলিলিএফ ও যেএসএস একযোট প্রচুি িলিমাণ Ak47 ও স্থাইিাি োগডােলড \\n(িানেলড) বিবাি লিয়ে ভািয ি লবচ্ছেন্ন বািীযিি যেযক লনয়ে আসযে। \\nThis text discusses the activities of the UPDF , a political organization advocating for the autonomy \\nof the Chittagong Hill Tracts region, which is inhabited by various indigenous groups including \\nChakmas. The language used portrays the UPDF's actions in a potentially problematic light. \\n \\nSocial Media Interaction 4\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review page_content for the file\n",
    "docs = loader.load()\n",
    "\n",
    "# Inspect the first document to verify its content and metadata.\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Split the text into chunks\n",
    "# ---------------------------\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=100)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------\n",
    "# Index chunks\n",
    "# -------------\n",
    "\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------\n",
    "# Define a Retrieval Tool (Method)\n",
    "# --------------------------------\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"\n",
    "    Retrieve information related to a user's query from the vector store.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to execute against the vector store.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing a serialized representation of the relevant documents \n",
    "               and the document objects themselves for further processing.\n",
    "    \"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to send\n",
    "# ------------------------------------------------------------------\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Generate a tool call for retrieval or formulate a response from the AI model.\n",
    "    \n",
    "    This function uses the AI model bound to the 'retrieve' tool to interpret the \n",
    "    current conversation state and determine if retrieval is required.\n",
    "    \n",
    "    Args:\n",
    "        state (MessagesState): An object holding ongoing conversation messages.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing updated messages, including the AI response.\n",
    "    \"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Step 2: Execute the retrieval via the Tool Node\n",
    "# ------------------------------------------------\n",
    "\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Step 3: Generate a final response using the retrieved\n",
    "#         content from the tool call(s).\n",
    "# -----------------------------------------------------\n",
    "\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Generate an AI response using retrieved content if available.\n",
    "    \n",
    "    This function compiles relevant content from any tool calls\n",
    "    and uses a system prompt to moderate content in a supportive and \n",
    "    inclusive manner before returning the final AI message.\n",
    "    \n",
    "    Args:\n",
    "        state (MessagesState): The conversation state, including user and AI messages.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the final AI response message.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"\"\"\n",
    "        As a supportive and nurturing content moderator like a teacher, evaluate whether this text could be perceived as hate speech, hurtful, or culturally insensitive. Consider if it marginalizes, reinforces stereotypes, or excludes any group. If so, provide constructive feedback by identifying concerns, explaining why they may be problematic, and suggesting more inclusive alternatives. Answer briefly and translate that in the Bengali language before responding.\n",
    "        \"\"\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Invoke the language model with the system prompt + conversation messages.\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "# Build and Compile the Conversation Graph\n",
    "# ------------------------------------\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "# Sets the graph's entry point (first step in the workflow).\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "\n",
    "# Here are conditional edges to decide whether a tool call is needed or to move on.\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "\n",
    "# The conversation flow moves from the tools node to the generate node, then ends.\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "আলহামদুলিল্লাহ প্রায় ৩০০ বছরের পূর্ব থেকে সংগঠিত কুন্ডু বাড়ির মেলা আর কোনো দিন সংগঠিত হবেনা। ইনশাল্লাহ।\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "এটি সত্যিই দুঃখজনক একটি সংবাদ। কুন্ডু বাড়ির মেলা যে প্রায় ৩০০ বছরের ঐতিহ্য বহন করে এসেছে, তা বাংলার সাংস্কৃতিক ও ঐতিহ্যগত একটি গুরুত্বপূর্ণ অংশ।  মেলার আয়োজন বন্ধ হওয়া একটি স্থানীয় সমাজের সাংস্কৃতিক জীবনেও প্রভাব ফেলে। \n",
      "\n",
      "আপনার মন্তব্যে \"ইনশাল্লাহ\" শব্দটি যুক্ত হওয়ার মাধ্যমে একটি আশা প্রকাশ করা হয়েছে যে, ভবিষ্যতে এটি আবার সংগঠিত হবে। সম্ভবত এটি সামাজিক সংহতি, ঐতিহ্য রক্ষা এবং ধর্মীয় বিশ্বাসের একটি উজ্জ্বল উদাহরণ।\n",
      "\n",
      "আপনার কি এই মেলা সম্পর্কে আরও কিছু জানার আছে?\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Example Usage with test input\n",
    "# -----------------------------\n",
    "\n",
    "input_message = \"আলহামদুলিল্লাহ প্রায় ৩০০ বছরের পূর্ব থেকে সংগঠিত কুন্ডু বাড়ির মেলা আর কোনো দিন সংগঠিত হবেনা। ইনশাল্লাহ।\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config, # I haven't defined it yet but we can if we want to later.\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "আলহামদুলিল্লাহ প্রায় ৩০০ বছরের পূর্ব থেকে সংগঠিত কুন্ডু বাড়ির মেলা আর কোনো দিন সংগঠিত হবেনা। ইনশাল্লাহ।\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_tTQXHdtUV7N3Y9XnXLnpZdLr)\n",
      " Call ID: call_tTQXHdtUV7N3Y9XnXLnpZdLr\n",
      "  Args:\n",
      "    query: কুন্ডু বাড়ির মেলা\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'author': 'Chauhan, Ankit Singh', 'creationdate': '2025-02-05T11:51:48-05:00', 'creator': 'Microsoft® Word for Microsoft 365', 'moddate': '2025-02-05T11:51:48-05:00', 'page': 2, 'page_label': '3', 'producer': 'Microsoft® Word for Microsoft 365', 'source': 'data/Social Media Interactions.pdf', 'total_pages': 3}\n",
      "Content: cultivation practices. Calling them \"junglee\" (jungle dwellers) is offensive and perpetuates harmful \n",
      "stereotypes about their knowledge and way of life. \n",
      "This type of language reflects a history of marginalization and discrimination faced by indigenous \n",
      "groups in Bangladesh. Their land rights have often been disregarded, and they have been \n",
      "stereotyped as backward or uncivilized. \n",
      "To address this issue, it's crucial to promote respect for cultural diversity and challenge harmful\n",
      "\n",
      "Source: {'author': 'Chauhan, Ankit Singh', 'creationdate': '2025-02-05T11:51:48-05:00', 'creator': 'Microsoft® Word for Microsoft 365', 'moddate': '2025-02-05T11:51:48-05:00', 'page': 1, 'page_label': '2', 'producer': 'Microsoft® Word for Microsoft 365', 'source': 'data/Social Media Interactions.pdf', 'total_pages': 3}\n",
      "Content: religious groups. Using terms like 'েঙ্গী' perpetuates harmful stereotypes and hinders \n",
      "understanding. Instead, it is important to acknowledge the complexities of the situation in the hills \n",
      "and engage in dialogue that respects the rights and dignity of all involved. \n",
      " \n",
      "Social Media Interaction 5 \n",
      "The user is sharing their experience of trying a popular dish from the Chakma, Marma and Rakhaine \n",
      "communities. There's no explicitly hateful or discriminatory language used. However, it's important\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "আপনার মন্তব্যে একটি গুরুত্বপূর্ণ সাংস্কৃতিক ঐতিহ্য এর ভবিষ্যৎ নিয়ে উদ্বেগ প্রকাশিত হচ্ছে। যদিও এটি একটি ব্যক্তিগত অনুভূতি হতে পারে, কিন্তু এটি কিয়দাংশে হতাশার প্রকাশ ঘটে। \n",
      "\n",
      "প্রথমে, \"আর কোনো দিন সংগঠিত হবেনা\" বলতে আপনি একটি চূড়ান্ত মন্তব্য করছেন, যা অন্যান্যদের অনুভূতির প্রতি সংবেদনশীলতা হারিয়ে ফেলতে পারে। এটি মানুষের মেলাকে এবং তাদের ঐতিহ্যকে সেলাই করতে পারে এবং এতে একটি নেতিবাচক ভাবনার সৃষ্টি হতে পারে।\n",
      "\n",
      "অভিযোগের পরিবর্তে, আপনি যদি পরিবর্তে আশাবাদী ও ইতিবাচক ভাষা ব্যবহার করেন, যেমন \"আমরা আশা করি যে কুন্ডু বাড়ির মেলা আবারও অনুষ্ঠিত হতে পারে\", তাহলে এটি ইউনিটি এবং ভবিষ্যতের সম্ভাবনা সম্পর্কে একটি উজ্জ্বল বার্তা পৌঁছাতে সাহায্য করবে।\n",
      "\n",
      "আমাদের সাংস্কৃতিক ঐতিহ্যগুলো একসাথে রক্ষার প্রচেষ্টা চালিয়ে যাওয়ার মহান গুরুত্ব রয়েছে, এবং যে কোনো ভাষা যা সেই ঐতিহ্যের মর্যাদা বৃদ্ধি করে তা ব্যবহার করা উচিত। \n",
      "\n",
      "**বাংলা ভাষায় অনুবাদ:** \n",
      "আপনার মন্তব্যে একটি গুরুত্বপূর্ণ সাংস্কৃতিক ঐতিহ্য এর ভবিষ্যৎ নিয়ে উদ্বেগ প্রকাশিত হচ্ছে। যদিও এটি একটি ব্যক্তিগত অনুভূতি হতে পারে, কিন্তু এটি কিয়দাংশে হতাশার প্রকাশ ঘটে। \n",
      "\n",
      "আপনার মন্তব্যের চূড়ান্ত হতে পারে যে, \"আর কোনো দিন সংগঠিত হবেনা\" এটি অন্যান্যদের অনুভূতির প্রতি সংবেদনশীলতা হারিয়ে ফেলতে পারে। \n",
      "\n",
      "আপনি যদি পরিবর্তে আশাবাদী ও ইতিবাচক ভাষা ব্যবহার করেন, যেমন \"আমরা আশা করি যে কুন্ডু বাড়ির মেলা আবারও অনুষ্ঠিত হতে পারে\", তাহলে এটি ইউনিটি এবং ভবিষ্যতের সম্ভাবনা সম্পর্কে একটি উজ্জ্বল বার্তা পৌঁছাতে সাহায্য করবে। \n",
      "\n",
      "আমাদের সাংস্কৃতিক ঐতিহ্যগুলো একসাথে রক্ষার প্রচেষ্টা চালিয়ে যাওয়ার মহান গুরুত্ব রয়েছে।\n"
     ]
    }
   ],
   "source": [
    "# You can re-run the graph with a follow up message to see how it responds.\n",
    "\n",
    "input_message = \"আলহামদুলিল্লাহ প্রায় ৩০০ বছরের পূর্ব থেকে সংগঠিত কুন্ডু বাড়ির মেলা আর কোনো দিন সংগঠিত হবেনা। ইনশাল্লাহ।\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minarc_env",
   "language": "python",
   "name": "minarc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
